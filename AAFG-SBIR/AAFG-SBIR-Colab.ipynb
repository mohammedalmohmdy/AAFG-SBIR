{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AAFG-SBIR â€” Colab/Jupyter Notebook\n\nReady-to-run steps for training/evaluating the Attention-Augmented FG-SBIR implementation.\n\n**Options to get the code:**\n- **GitHub** (recommended):\n  1) Create a new empty repo on your account and push the code from this ZIP.\n  2) Replace `<your-username>`/`<your-repo>` below and run the `git clone` cell.\n- **Local upload**: If running locally, open this notebook from inside the project root."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "#@title Clone your GitHub repo here (after you push)\nGIT_REPO = \"https://github.com/USERNAME/REPO.git\"  #@param {type:\"string\"}\nGIT_DIR  = \"\"  #@param {type:\"string\"}\n\nimport os, sys, subprocess\n\nif GIT_REPO and GIT_REPO != \"https://github.com/USERNAME/REPO.git\":\n    print(\"Cloning:\", GIT_REPO)\n    !git clone $GIT_REPO\n    if not GIT_DIR:\n        # infer directory from repo URL\n        GIT_DIR = os.path.splitext(os.path.basename(GIT_REPO))[0]\n    %cd $GIT_DIR\nelse:\n    print(\"[Info] Set GIT_REPO to your GitHub repository URL after you push the code.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n#@title Install requirements\n!python -m pip install -q -r requirements.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n#@title Check GPU / environment\nimport torch, platform, sys\nprint(\"Python:\", sys.version)\nprint(\"Platform:\", platform.platform())\nprint(\"Torch:\", torch.__version__)\nprint(\"CUDA available:\", torch.cuda.is_available())\nif torch.cuda.is_available():\n    print(\"CUDA device:\", torch.cuda.get_device_name(0))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare tiny smoke dataset\nThis creates minimal images and CSVs to verify the training/evaluation loop without downloading full datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n#@title Create tiny sample images and CSVs (Sketchy-style layout)\nfrom PIL import Image, ImageDraw\nimport os, pandas as pd\n\nroot = \"DATA/Sketchy\"\nsk_dir = os.path.join(root, \"sketches\")\nim_dir = os.path.join(root, \"images\")\nos.makedirs(sk_dir, exist_ok=True)\nos.makedirs(im_dir, exist_ok=True)\n\n# Make a couple of tiny 224x224 images\ndef make_img(path, text):\n    img = Image.new(\"RGB\", (224,224), color=(240,240,240))\n    d = ImageDraw.Draw(img)\n    d.text((10,10), text, fill=(0,0,0))\n    img.save(path)\n\nmake_img(os.path.join(sk_dir, \"example1.png\"), \"sketch-1\")\nmake_img(os.path.join(im_dir, \"example1.jpg\"), \"image-1\")\nmake_img(os.path.join(sk_dir, \"example2.png\"), \"sketch-2\")\nmake_img(os.path.join(im_dir, \"example2.jpg\"), \"image-2\")\n\n# Build tiny CSVs\nimport pandas as pd\ntrain = pd.DataFrame([\n    {\"path_sketch\":\"sketches/example1.png\", \"path_image\":\"images/example1.jpg\", \"label\":0},\n])\nval = pd.DataFrame([\n    {\"path_sketch\":\"sketches/example2.png\", \"path_image\":\"images/example2.jpg\", \"label\":0},\n])\ntest = val.copy()\n\ntrain.to_csv(os.path.join(root, \"tiny_train.csv\"), index=False)\nval.to_csv(os.path.join(root, \"tiny_val.csv\"), index=False)\ntest.to_csv(os.path.join(root, \"index_test.csv\"), index=False)\n\nprint(\"Created tiny dataset under\", root)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run unit test (forward pass)\nVerifies shapes and L2-normalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n!python tests/test_forward.py\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train (smoke run)\nTwo epochs on the tiny dataset to validate the training loop and logging."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n!python scripts/train.py \\\n  --data_root DATA/Sketchy \\\n  --train_csv tiny_train.csv \\\n  --val_csv tiny_val.csv \\\n  --epochs 2 \\\n  --batch_size 2 \\\n  --lr 1e-4 \\\n  --margin 0.2 \\\n  --log_dir runs/smoke\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate on the tiny test set\nThis will print mAP and P@K for the small sample."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "\n!python scripts/eval.py \\\n  --data_root DATA/Sketchy \\\n  --test_csv index_test.csv \\\n  --ckpt checkpoints/best.pt \\\n  --batch_size 2\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}